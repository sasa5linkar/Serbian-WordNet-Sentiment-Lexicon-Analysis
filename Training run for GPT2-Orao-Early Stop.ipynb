{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a24020-7015-4083-bdbd-1347029fa855",
   "metadata": {},
   "source": [
    "# Fine-Tuning and Performance Evaluation of GPT2-Orao based Models for Sentiment Classification with Early Stopping\n",
    "\n",
    "In this Jupyter notebook, we delve into the crucial steps of our Natural Language Processing (NLP) project - fine-tuning our preprocessed BERT models on the Serbian Wordnet training data, and assessing their performance. \n",
    "\n",
    "Our primary objective is to adapt GPT2 models to effectively classify sentiments, leveraging a semi-automated, iterative approach that uses seed words and expands them based on their relationships in WordNet. \n",
    "\n",
    "The performance evaluation metrics are instrumental in assessing the success of our fine-tuning process. We will analyze these metrics in two ways:\n",
    "\n",
    "1. **In-notebook Review:** For an immediate performance evaluation, we will print the confusion matrix and classification reports within this notebook.\n",
    "\n",
    "2. **Persistent Reports:** We'll create a lasting record of our results by storing these metrics in a separate 'reports' folder. This approach facilitates progress trackingover time, and enables comparisons among different models and fine-tuning iterations.\n",
    "\n",
    "Keep in mind that the fine-tuning and evaluation processes are iterative. Based on our results and insights, we may need to adjust our strategies and fine-tune our models \n",
    "ifferently.\n",
    "\n",
    "Throughout this notebook, we will go through:\n",
    "\n",
    "1. **Model Training:** Execution of Python scripts for fine-tuning our GPT2 models on the training set.\n",
    "2. **Model Testing:** Performance evaluation of the newly fine-tuned models on our test data.\n",
    "3. **Results Analysis:** Examination, interpretation, and storage of the confusion matrices and classifIn our previous work, we fine-tuned our BERT models for sentiment classification on the Serbian Wordnet training data. However, the models appeared to be overfitting. Overfitting is a common problem in machine learning where a model learns the training data too well, essentially memorizing it, rather than generalizing from it. This means that it performs poorly on unseen data, which is a big problem if we want our models to be applicable to real-world data.\n",
    "\n",
    "To overcome this issue, we're going to introduce early stopping in this notebook. Early stopping is a method used to prevent overfitting by ending the training process before the learner passes a certain point of over-specialization, i.e., before the model starts to overfit.\n",
    "\n",
    "We'll GPT2-Orao based models, but this time, we'll include an early stopping line in our trainer call. \n",
    "!\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7e9a2-0291-484e-bb30-1e04d1799faa",
   "metadata": {},
   "source": [
    "### Importing Required Modules\n",
    "\n",
    "In this initial code cell, we import the necessary modules that contain functions for training and testing our BERT models. The modules imported are:\n",
    "\n",
    "1. **`trainSRGPT`:** This module contains the `train_model` and `test_model` functions for handling the training and testing processes respectively. The GPT2 model used in this module is the \"Jerteh\" GPT2 - Orao model, which is pre-trained exclusively on the Serbian language using a GPT2 architecture. It is tailored to deal with the specificities of the Serbian language, managing everything from data preprocessing to model training, testing, and memory management for GPU use. Also 'test_model_local' and 'upload_local_model_to_hub' had been added since there was some problem with incorrcte uploding. In this way it can be checked if local and model uploded on site are the same.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3670d233-eeca-4faf-90a9-a2a65d777043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import trainSRGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef7d75-69bc-4e6d-a451-24947bc2cdf1",
   "metadata": {},
   "source": [
    "## Iteration 0 - Training and Testing\n",
    "In this section, we use the data from the 0th iteration of the semi-automatic iterative algorithm for both Positive and Negative sentiment classification to train and test our BERT models\n",
    "\n",
    "s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feed41c8-2480-47ac-9d7f-a9d66ab43d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9337eb2a76a448edb65b4dcf753c49d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2667 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7db1fec0624eda910feebfcde0d73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10665 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTPOS0 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08c3cb09d0f426ab2d9ee1fe3d72407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 8.15k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a325b67c65544dbaa483969eab2eba6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 4.30k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b9da0b80064c438634838748912ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  23%|##3       | 1.00k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9ac0dfc7b74c709c0575e7d633a1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0789, 'learning_rate': 1.9882783195798953e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0457, 'learning_rate': 1.97655663915979e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0524, 'learning_rate': 1.964834958739685e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0416, 'learning_rate': 1.9531132783195802e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0315, 'learning_rate': 1.941391597899475e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3460ec48be468cbacd3807a5db9c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12009615451097488, 'eval_f1': 0.3666666666666667, 'eval_runtime': 57.8955, 'eval_samples_per_second': 46.066, 'eval_steps_per_second': 46.066, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0247, 'learning_rate': 1.92966991747937e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0377, 'learning_rate': 1.917948237059265e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0225, 'learning_rate': 1.90622655663916e-05, 'epoch': 1.5}\n",
      "{'loss': 0.043, 'learning_rate': 1.894504876219055e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0279, 'learning_rate': 1.88278319579895e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec41fb8fb1cf4598aba910ef998d2523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10047691315412521, 'eval_f1': 0.25641025641025644, 'eval_runtime': 58.9911, 'eval_samples_per_second': 45.21, 'eval_steps_per_second': 45.21, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0057, 'learning_rate': 1.8710615153788448e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0182, 'learning_rate': 1.85933983495874e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0567, 'learning_rate': 1.847618154538635e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0038, 'learning_rate': 1.8358964741185298e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0169, 'learning_rate': 1.8241747936984245e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502c12902fba4b6f862b8e4608e07c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11446953564882278, 'eval_f1': 0.24242424242424246, 'eval_runtime': 60.327, 'eval_samples_per_second': 44.209, 'eval_steps_per_second': 44.209, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0344, 'learning_rate': 1.8124531132783196e-05, 'epoch': 3.0}\n",
      "{'loss': 0.003, 'learning_rate': 1.8007314328582147e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0099, 'learning_rate': 1.7890097524381094e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0033, 'learning_rate': 1.7772880720180045e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0059, 'learning_rate': 1.7655663915978996e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0131, 'learning_rate': 1.7538447111777944e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f66af21aac4118b9759327001355ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12751102447509766, 'eval_f1': 0.1935483870967742, 'eval_runtime': 58.7251, 'eval_samples_per_second': 45.415, 'eval_steps_per_second': 45.415, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7421230307576895e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0051, 'learning_rate': 1.7304013503375846e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0, 'learning_rate': 1.7186796699174793e-05, 'epoch': 4.5}\n",
      "{'loss': 0.009, 'learning_rate': 1.7069579894973744e-05, 'epoch': 4.69}\n",
      "{'loss': 0.011, 'learning_rate': 1.6952363090772695e-05, 'epoch': 4.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f611c03d69486daa8b8b52dfcf7481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13059721887111664, 'eval_f1': 0.07692307692307693, 'eval_runtime': 58.7783, 'eval_samples_per_second': 45.374, 'eval_steps_per_second': 45.374, 'epoch': 5.0}\n",
      "{'train_runtime': 10546.1245, 'train_samples_per_second': 32.361, 'train_steps_per_second': 8.089, 'train_loss': 0.022838059998659233, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbca5876692436abad9ef81f9ff84c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/SRGPTSENTPOS0\n",
      "   6be9a5a..3fdbc0f  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/SRGPTSENTPOS0\n",
      "   3fdbc0f..29fd26c  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "    6.42 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(0, \"POS\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0f850-03e1-48f7-a151-9c7bd3af3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4392   16]\n",
      " [  17   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4408\n",
      "           1       0.56      0.54      0.55        37\n",
      "\n",
      "    accuracy                           0.99      4445\n",
      "   macro avg       0.78      0.77      0.77      4445\n",
      "weighted avg       0.99      0.99      0.99      4445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7b260-2358-4654-8e2f-495237675567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c21eda5a08e4d0691b4f8bab91522e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbb657f-36d8-4f0b-a0a2-2c92dfa03bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.2.0.dev20230928)\n",
      "    Python  3.11.5 (you have 3.11.4)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4392   16]\n",
      " [  17   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4408\n",
      "           1       0.56      0.54      0.55        37\n",
      "\n",
      "    accuracy                           0.99      4445\n",
      "   macro avg       0.78      0.77      0.77      4445\n",
      "weighted avg       0.99      0.99      0.99      4445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf289631-0b42-4fb0-9d1d-5f111bbcc7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6897376768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a5c5209de4487eaed42b5076e4a7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2667 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b1a11f661c4dd9960b2fc0f7565410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10665 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTNEG0 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faef7327601d45348a056691076be9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 16.4k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fe54cf145244f6b0b1c78fe2c5743d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 4.30k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adcaae084c7484ba8813bd41301657e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  23%|##3       | 1.00k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bd56e27b2547ce84f33a280d3872c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0857, 'learning_rate': 1.9882783195798953e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0721, 'learning_rate': 1.97655663915979e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0439, 'learning_rate': 1.964834958739685e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0735, 'learning_rate': 1.9531132783195802e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0521, 'learning_rate': 1.941391597899475e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe221ac8cc4f4ff3b91250f268362b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09305841475725174, 'eval_f1': 0.4358974358974359, 'eval_runtime': 145.7993, 'eval_samples_per_second': 18.292, 'eval_steps_per_second': 18.292, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.053, 'learning_rate': 1.92966991747937e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0446, 'learning_rate': 1.917948237059265e-05, 'epoch': 1.31}\n",
      "{'loss': 0.028, 'learning_rate': 1.90622655663916e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0602, 'learning_rate': 1.894504876219055e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0511, 'learning_rate': 1.88278319579895e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3307e23af9149b9a5c92ce09df5e870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12556378543376923, 'eval_f1': 0.45614035087719296, 'eval_runtime': 148.2646, 'eval_samples_per_second': 17.988, 'eval_steps_per_second': 17.988, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0502, 'learning_rate': 1.8710615153788448e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0205, 'learning_rate': 1.85933983495874e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0453, 'learning_rate': 1.847618154538635e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0194, 'learning_rate': 1.8358964741185298e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0173, 'learning_rate': 1.8241747936984245e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5294211538e649f4a5b8b7ef66d40018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18492776155471802, 'eval_f1': 0.41935483870967744, 'eval_runtime': 152.5787, 'eval_samples_per_second': 17.48, 'eval_steps_per_second': 17.48, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0123, 'learning_rate': 1.8124531132783196e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0038, 'learning_rate': 1.8007314328582147e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0, 'learning_rate': 1.7890097524381094e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0079, 'learning_rate': 1.7772880720180045e-05, 'epoch': 3.56}\n",
      "{'loss': 0.011, 'learning_rate': 1.7655663915978996e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0091, 'learning_rate': 1.7538447111777944e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8febca55064d7b885cb11e1111ff8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1939464956521988, 'eval_f1': 0.34782608695652173, 'eval_runtime': 143.395, 'eval_samples_per_second': 18.599, 'eval_steps_per_second': 18.599, 'epoch': 4.0}\n",
      "{'train_runtime': 14574.2518, 'train_samples_per_second': 23.417, 'train_steps_per_second': 5.854, 'train_loss': 0.03567274771457086, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a846ce38fe4a485d9f4bb4b284a2982f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at a389eea1e06718e42191d0023420c3a1cb0a55cb but expected d6d012c115db433bfc7a5feb851c584f9402c310        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTNEG0'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push attempt 1 failed with error: remote: error: cannot lock ref 'refs/heads/main': is at a389eea1e06718e42191d0023420c3a1cb0a55cb but expected d6d012c115db433bfc7a5feb851c584f9402c310        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTNEG0'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      "   a389eea..acf49c4  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "    6.42 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(0, \"NEG\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d007fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4370   21]\n",
      " [  30   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4391\n",
      "           1       0.53      0.44      0.48        54\n",
      "\n",
      "    accuracy                           0.99      4445\n",
      "   macro avg       0.76      0.72      0.74      4445\n",
      "weighted avg       0.99      0.99      0.99      4445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05a213-3c1c-4366-aa41-5813b4d72b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76758c2a495f4c36ae31b5f681db6312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc145527-25c0-4935-8379-e17151dfe81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6dd28efaac4a42b1c12acdd860928f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaacbc40300d4e458f6751713cc514c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b25fecb5a6409980df55f29841c5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4370   21]\n",
      " [  30   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4391\n",
      "           1       0.53      0.44      0.48        54\n",
      "\n",
      "    accuracy                           0.99      4445\n",
      "   macro avg       0.76      0.72      0.74      4445\n",
      "weighted avg       0.99      0.99      0.99      4445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308e0ba-40f7-44b4-b4a7-612be0a1f701",
   "metadata": {},
   "source": [
    "## Iteration 2 - Training and Testing\n",
    "In this section, we use the data from the 2nd iteration of the semi-automatic iterative algorithm for both Positive and Negative sentiment classification to train and test our BERT models.\n",
    "\n",
    "y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387d4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecebc8c0950b479e8471b367f80084be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2698 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60ed9cad71e4df5a608f7d79839e38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10788 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTPOS2 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5785244df12240819c0a191f18869ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 6.25k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4a85d7da3f4ff5ad95c819583aab4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 4.30k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acf2b3e6d444c4a9a5e201620b4aa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  23%|##3       | 1.00k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a0faa6172d4e1db99369c81108ac67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0521, 'learning_rate': 1.988413051538747e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0312, 'learning_rate': 1.9768261030774935e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0359, 'learning_rate': 1.9652391546162403e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0178, 'learning_rate': 1.953652206154987e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0314, 'learning_rate': 1.942065257693734e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c502624f01d47d19627aeb69a00afb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16743789613246918, 'eval_f1': 0.5111111111111112, 'eval_runtime': 155.7633, 'eval_samples_per_second': 17.321, 'eval_steps_per_second': 17.321, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0206, 'learning_rate': 1.9304783092324804e-05, 'epoch': 1.11}\n",
      "{'loss': 0.028, 'learning_rate': 1.9188913607712273e-05, 'epoch': 1.3}\n",
      "{'loss': 0.023, 'learning_rate': 1.907304412309974e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0167, 'learning_rate': 1.895717463848721e-05, 'epoch': 1.67}\n",
      "{'loss': 0.0236, 'learning_rate': 1.8841305153874677e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a70cfaea09043e6aa85304268ab77c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16873560845851898, 'eval_f1': 0.4307692307692308, 'eval_runtime': 159.0412, 'eval_samples_per_second': 16.964, 'eval_steps_per_second': 16.964, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0214, 'learning_rate': 1.8725435669262146e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0058, 'learning_rate': 1.8609566184649614e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0127, 'learning_rate': 1.849369670003708e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0173, 'learning_rate': 1.8377827215424547e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0094, 'learning_rate': 1.8261957730812015e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0407, 'learning_rate': 1.8146088246199484e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ecf79a7a1e4183ba06a2c68147f177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15711432695388794, 'eval_f1': 0.4, 'eval_runtime': 59.5318, 'eval_samples_per_second': 45.32, 'eval_steps_per_second': 45.32, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0205, 'learning_rate': 1.8030218761586952e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0128, 'learning_rate': 1.7914349276974417e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0119, 'learning_rate': 1.7798479792361885e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0112, 'learning_rate': 1.7682610307749353e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0086, 'learning_rate': 1.756674082313682e-05, 'epoch': 3.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d4afc884ae44649ed8b9570e0939c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34660327434539795, 'eval_f1': 0.34374999999999994, 'eval_runtime': 152.1019, 'eval_samples_per_second': 17.738, 'eval_steps_per_second': 17.738, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0066, 'learning_rate': 1.7450871338524286e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0156, 'learning_rate': 1.7335001853911755e-05, 'epoch': 4.26}\n",
      "{'loss': 0.015, 'learning_rate': 1.7219132369299223e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0212, 'learning_rate': 1.710326288468669e-05, 'epoch': 4.63}\n",
      "{'loss': 0.007, 'learning_rate': 1.6987393400074156e-05, 'epoch': 4.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe995161bad4b20ae37275cb7bf7bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19816473126411438, 'eval_f1': 0.37499999999999994, 'eval_runtime': 142.8261, 'eval_samples_per_second': 18.89, 'eval_steps_per_second': 18.89, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0135, 'learning_rate': 1.6871523915461624e-05, 'epoch': 5.01}\n",
      "{'loss': 0.0181, 'learning_rate': 1.6755654430849093e-05, 'epoch': 5.19}\n",
      "{'loss': 0.0085, 'learning_rate': 1.663978494623656e-05, 'epoch': 5.38}\n",
      "{'loss': 0.0323, 'learning_rate': 1.6523915461624026e-05, 'epoch': 5.56}\n",
      "{'loss': 0.0044, 'learning_rate': 1.6408045977011494e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0091, 'learning_rate': 1.6292176492398962e-05, 'epoch': 5.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f250962a73e84148a7711012caeda12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20229972898960114, 'eval_f1': 0.34920634920634924, 'eval_runtime': 145.5307, 'eval_samples_per_second': 18.539, 'eval_steps_per_second': 18.539, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.005, 'learning_rate': 1.617630700778643e-05, 'epoch': 6.12}\n",
      "{'loss': 0.0, 'learning_rate': 1.60604375231739e-05, 'epoch': 6.3}\n",
      "{'loss': 0.0047, 'learning_rate': 1.5944568038561367e-05, 'epoch': 6.49}\n",
      "{'loss': 0.0112, 'learning_rate': 1.5828698553948835e-05, 'epoch': 6.67}\n",
      "{'loss': 0.0071, 'learning_rate': 1.57128290693363e-05, 'epoch': 6.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da75f7556c5487d94d1452f616488a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24766495823860168, 'eval_f1': 0.36781609195402304, 'eval_runtime': 134.184, 'eval_samples_per_second': 20.107, 'eval_steps_per_second': 20.107, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0083, 'learning_rate': 1.559695958472377e-05, 'epoch': 7.04}\n",
      "{'loss': 0.0, 'learning_rate': 1.5481090100111237e-05, 'epoch': 7.23}\n",
      "{'loss': 0.0177, 'learning_rate': 1.5365220615498705e-05, 'epoch': 7.42}\n",
      "{'loss': 0.0167, 'learning_rate': 1.5249351130886171e-05, 'epoch': 7.6}\n",
      "{'loss': 0.0127, 'learning_rate': 1.5133481646273638e-05, 'epoch': 7.79}\n",
      "{'loss': 0.0075, 'learning_rate': 1.5017612161661106e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144566233666488692afaef436527fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15560871362686157, 'eval_f1': 0.37499999999999994, 'eval_runtime': 139.1034, 'eval_samples_per_second': 19.396, 'eval_steps_per_second': 19.396, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0093, 'learning_rate': 1.4901742677048574e-05, 'epoch': 8.16}\n",
      "{'loss': 0.0021, 'learning_rate': 1.4785873192436043e-05, 'epoch': 8.34}\n",
      "{'loss': 0.0128, 'learning_rate': 1.4670003707823508e-05, 'epoch': 8.53}\n",
      "{'loss': 0.0157, 'learning_rate': 1.4554134223210976e-05, 'epoch': 8.71}\n",
      "{'loss': 0.0089, 'learning_rate': 1.4438264738598444e-05, 'epoch': 8.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b758255676914d1bbfd658a9b25c9cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2155970335006714, 'eval_f1': 0.37288135593220345, 'eval_runtime': 141.4184, 'eval_samples_per_second': 19.078, 'eval_steps_per_second': 19.078, 'epoch': 9.0}\n",
      "{'train_runtime': 31255.3326, 'train_samples_per_second': 11.045, 'train_steps_per_second': 2.761, 'train_loss': 0.015349580170902575, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57c333a8e2f48b9a143fb498b411b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at 48a972d7f8072ea4f4363b072243bc65e0fa98da but expected cbf7e352c17137cdba43e4b2e8e8cd0928934858        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTPOS2\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTPOS2'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push attempt 1 failed with error: remote: error: cannot lock ref 'refs/heads/main': is at 48a972d7f8072ea4f4363b072243bc65e0fa98da but expected cbf7e352c17137cdba43e4b2e8e8cd0928934858        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTPOS2\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTPOS2'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "To https://huggingface.co/Tanor/SRGPTSENTPOS2\n",
      "   48a972d..4a8fd35  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "    6.42 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(2, \"POS\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e186076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4400   30]\n",
      " [  51   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4430\n",
      "           1       0.33      0.23      0.27        66\n",
      "\n",
      "    accuracy                           0.98      4496\n",
      "   macro avg       0.66      0.61      0.63      4496\n",
      "weighted avg       0.98      0.98      0.98      4496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(2, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522e6f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce1d89908b4bfdb6d073abf6f6a989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(2, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d10b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ceae51d98748549cb43a82d9306d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3783032431294ce782c3afceacd28448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17567d1ff5614765b1fe90af3213ceb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4400   30]\n",
      " [  51   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4430\n",
      "           1       0.33      0.23      0.27        66\n",
      "\n",
      "    accuracy                           0.98      4496\n",
      "   macro avg       0.66      0.61      0.63      4496\n",
      "weighted avg       0.98      0.98      0.98      4496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(2, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1e3a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6896721408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029381c07134e67b18b122c4d6f4696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2698 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a10c5c36ede437f98550838d4077749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10788 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTNEG2 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753cedf3c226408ea66d89b1610eb813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 15.4k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6e307fed3a4bea89653e81acdbfc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 4.30k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a61ac6a786e49c79229b5b5190f038e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  23%|##3       | 1.00k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb8dba73aef4091b680f3e3ec620b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0638, 'learning_rate': 1.988413051538747e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0715, 'learning_rate': 1.9768261030774935e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0648, 'learning_rate': 1.9652391546162403e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0802, 'learning_rate': 1.953652206154987e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0592, 'learning_rate': 1.942065257693734e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477f940ce96e4e999ce6b2528caf8cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15903839468955994, 'eval_f1': 0.22641509433962262, 'eval_runtime': 152.6273, 'eval_samples_per_second': 17.677, 'eval_steps_per_second': 17.677, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.051, 'learning_rate': 1.9304783092324804e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0404, 'learning_rate': 1.9188913607712273e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0413, 'learning_rate': 1.907304412309974e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0624, 'learning_rate': 1.895717463848721e-05, 'epoch': 1.67}\n",
      "{'loss': 0.0058, 'learning_rate': 1.8841305153874677e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784b546b660140b389f35b97196cd411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1645973026752472, 'eval_f1': 0.28571428571428575, 'eval_runtime': 163.3309, 'eval_samples_per_second': 16.519, 'eval_steps_per_second': 16.519, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0486, 'learning_rate': 1.8725435669262146e-05, 'epoch': 2.04}\n",
      "{'loss': 0.032, 'learning_rate': 1.8609566184649614e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0497, 'learning_rate': 1.849369670003708e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0295, 'learning_rate': 1.8377827215424547e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0404, 'learning_rate': 1.8261957730812015e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0169, 'learning_rate': 1.8146088246199484e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e58e796c541408f89fad1929c7d389b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1921713799238205, 'eval_f1': 0.4324324324324324, 'eval_runtime': 153.8194, 'eval_samples_per_second': 17.54, 'eval_steps_per_second': 17.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0106, 'learning_rate': 1.8030218761586952e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0258, 'learning_rate': 1.7914349276974417e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0186, 'learning_rate': 1.7798479792361885e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0257, 'learning_rate': 1.7682610307749353e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0223, 'learning_rate': 1.756674082313682e-05, 'epoch': 3.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e67c4b57d141858da69b2f08c749bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1810169517993927, 'eval_f1': 0.4788732394366197, 'eval_runtime': 152.3424, 'eval_samples_per_second': 17.71, 'eval_steps_per_second': 17.71, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0126, 'learning_rate': 1.7450871338524286e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0095, 'learning_rate': 1.7335001853911755e-05, 'epoch': 4.26}\n",
      "{'loss': 0.007, 'learning_rate': 1.7219132369299223e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0268, 'learning_rate': 1.710326288468669e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0123, 'learning_rate': 1.6987393400074156e-05, 'epoch': 4.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8efc5e55a5e42199434b87d3956fdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1618320196866989, 'eval_f1': 0.380952380952381, 'eval_runtime': 144.7833, 'eval_samples_per_second': 18.635, 'eval_steps_per_second': 18.635, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0185, 'learning_rate': 1.6871523915461624e-05, 'epoch': 5.01}\n",
      "{'loss': 0.013, 'learning_rate': 1.6755654430849093e-05, 'epoch': 5.19}\n",
      "{'loss': 0.0202, 'learning_rate': 1.663978494623656e-05, 'epoch': 5.38}\n",
      "{'loss': 0.0197, 'learning_rate': 1.6523915461624026e-05, 'epoch': 5.56}\n",
      "{'loss': 0.0014, 'learning_rate': 1.6408045977011494e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0185, 'learning_rate': 1.6292176492398962e-05, 'epoch': 5.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9192273c10ed41ee9f8a5f8b31c21939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2078782469034195, 'eval_f1': 0.4931506849315068, 'eval_runtime': 57.3235, 'eval_samples_per_second': 47.066, 'eval_steps_per_second': 47.066, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0036, 'learning_rate': 1.617630700778643e-05, 'epoch': 6.12}\n",
      "{'loss': 0.0098, 'learning_rate': 1.60604375231739e-05, 'epoch': 6.3}\n",
      "{'loss': 0.0148, 'learning_rate': 1.5944568038561367e-05, 'epoch': 6.49}\n",
      "{'loss': 0.0148, 'learning_rate': 1.5828698553948835e-05, 'epoch': 6.67}\n",
      "{'loss': 0.0101, 'learning_rate': 1.57128290693363e-05, 'epoch': 6.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0decb2e154f2416bb98e6f6069a11e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20985624194145203, 'eval_f1': 0.3582089552238805, 'eval_runtime': 57.9598, 'eval_samples_per_second': 46.549, 'eval_steps_per_second': 46.549, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0122, 'learning_rate': 1.559695958472377e-05, 'epoch': 7.04}\n",
      "{'loss': 0.0091, 'learning_rate': 1.5481090100111237e-05, 'epoch': 7.23}\n",
      "{'loss': 0.0047, 'learning_rate': 1.5365220615498705e-05, 'epoch': 7.42}\n",
      "{'loss': 0.0054, 'learning_rate': 1.5249351130886171e-05, 'epoch': 7.6}\n",
      "{'loss': 0.0007, 'learning_rate': 1.5133481646273638e-05, 'epoch': 7.79}\n",
      "{'loss': 0.0157, 'learning_rate': 1.5017612161661106e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720e1cd37d954c1583e713de7b29ff4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20124344527721405, 'eval_f1': 0.3478260869565218, 'eval_runtime': 58.0391, 'eval_samples_per_second': 46.486, 'eval_steps_per_second': 46.486, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0076, 'learning_rate': 1.4901742677048574e-05, 'epoch': 8.16}\n",
      "{'loss': 0.0004, 'learning_rate': 1.4785873192436043e-05, 'epoch': 8.34}\n",
      "{'loss': 0.0047, 'learning_rate': 1.4670003707823508e-05, 'epoch': 8.53}\n",
      "{'loss': 0.0205, 'learning_rate': 1.4554134223210976e-05, 'epoch': 8.71}\n",
      "{'loss': 0.0065, 'learning_rate': 1.4438264738598444e-05, 'epoch': 8.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de197a787c0843589301b9cb5222f65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21818579733371735, 'eval_f1': 0.4, 'eval_runtime': 57.4969, 'eval_samples_per_second': 46.924, 'eval_steps_per_second': 46.924, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.4322395253985912e-05, 'epoch': 9.08}\n",
      "{'loss': 0.0038, 'learning_rate': 1.4206525769373379e-05, 'epoch': 9.27}\n",
      "{'loss': 0.0165, 'learning_rate': 1.4090656284760846e-05, 'epoch': 9.45}\n",
      "{'loss': 0.0075, 'learning_rate': 1.3974786800148314e-05, 'epoch': 9.64}\n",
      "{'loss': 0.0059, 'learning_rate': 1.3858917315535782e-05, 'epoch': 9.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d427b92d00451eba4504cf278514f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20864936709403992, 'eval_f1': 0.380952380952381, 'eval_runtime': 57.6415, 'eval_samples_per_second': 46.807, 'eval_steps_per_second': 46.807, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'learning_rate': 1.3743047830923249e-05, 'epoch': 10.01}\n",
      "{'loss': 0.001, 'learning_rate': 1.3627178346310717e-05, 'epoch': 10.2}\n",
      "{'loss': 0.0044, 'learning_rate': 1.3511308861698185e-05, 'epoch': 10.38}\n",
      "{'loss': 0.0179, 'learning_rate': 1.3395439377085653e-05, 'epoch': 10.57}\n",
      "{'loss': 0.004, 'learning_rate': 1.3279569892473118e-05, 'epoch': 10.75}\n",
      "{'loss': 0.0085, 'learning_rate': 1.3163700407860586e-05, 'epoch': 10.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83c57f494a44874ba973e5b3b27d263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24980825185775757, 'eval_f1': 0.3880597014925373, 'eval_runtime': 57.5545, 'eval_samples_per_second': 46.877, 'eval_steps_per_second': 46.877, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.3047830923248055e-05, 'epoch': 11.12}\n",
      "{'loss': 0.0076, 'learning_rate': 1.2931961438635523e-05, 'epoch': 11.31}\n",
      "{'loss': 0.0, 'learning_rate': 1.281609195402299e-05, 'epoch': 11.49}\n",
      "{'loss': 0.0014, 'learning_rate': 1.2700222469410458e-05, 'epoch': 11.68}\n",
      "{'loss': 0.0086, 'learning_rate': 1.2584352984797924e-05, 'epoch': 11.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249e5d0e967c46319d96e02038e80498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2321060597896576, 'eval_f1': 0.34375, 'eval_runtime': 59.2032, 'eval_samples_per_second': 45.572, 'eval_steps_per_second': 45.572, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.01, 'learning_rate': 1.2468483500185393e-05, 'epoch': 12.05}\n",
      "{'loss': 0.007, 'learning_rate': 1.235261401557286e-05, 'epoch': 12.24}\n",
      "{'loss': 0.0028, 'learning_rate': 1.2236744530960327e-05, 'epoch': 12.42}\n",
      "{'loss': 0.0094, 'learning_rate': 1.2120875046347796e-05, 'epoch': 12.61}\n",
      "{'loss': 0.0031, 'learning_rate': 1.2005005561735264e-05, 'epoch': 12.79}\n",
      "{'loss': 0.0003, 'learning_rate': 1.1889136077122729e-05, 'epoch': 12.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6efb22dfba440469aa24cf87c1f038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2663653790950775, 'eval_f1': 0.38235294117647056, 'eval_runtime': 58.6707, 'eval_samples_per_second': 45.985, 'eval_steps_per_second': 45.985, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0098, 'learning_rate': 1.1773266592510197e-05, 'epoch': 13.16}\n",
      "{'loss': 0.0, 'learning_rate': 1.1657397107897665e-05, 'epoch': 13.35}\n",
      "{'loss': 0.0078, 'learning_rate': 1.1541527623285134e-05, 'epoch': 13.53}\n",
      "{'loss': 0.0087, 'learning_rate': 1.14256581386726e-05, 'epoch': 13.72}\n",
      "{'loss': 0.0, 'learning_rate': 1.1309788654060068e-05, 'epoch': 13.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5bd73d33384561967449d75a627685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2587439715862274, 'eval_f1': 0.4057971014492754, 'eval_runtime': 59.2098, 'eval_samples_per_second': 45.567, 'eval_steps_per_second': 45.567, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.1193919169447535e-05, 'epoch': 14.09}\n",
      "{'loss': 0.0154, 'learning_rate': 1.1078049684835003e-05, 'epoch': 14.28}\n",
      "{'loss': 0.0001, 'learning_rate': 1.096218020022247e-05, 'epoch': 14.46}\n",
      "{'loss': 0.0011, 'learning_rate': 1.0846310715609938e-05, 'epoch': 14.65}\n",
      "{'loss': 0.0, 'learning_rate': 1.0730441230997406e-05, 'epoch': 14.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3b64ff69ef4b66a5609cdfec6cffd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.271511435508728, 'eval_f1': 0.34375, 'eval_runtime': 57.6542, 'eval_samples_per_second': 46.796, 'eval_steps_per_second': 46.796, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0086, 'learning_rate': 1.0614571746384871e-05, 'epoch': 15.02}\n",
      "{'loss': 0.0017, 'learning_rate': 1.049870226177234e-05, 'epoch': 15.2}\n",
      "{'loss': 0.0, 'learning_rate': 1.0382832777159808e-05, 'epoch': 15.39}\n",
      "{'loss': 0.0017, 'learning_rate': 1.0266963292547276e-05, 'epoch': 15.57}\n",
      "{'loss': 0.0054, 'learning_rate': 1.0151093807934743e-05, 'epoch': 15.76}\n",
      "{'loss': 0.0043, 'learning_rate': 1.003522432332221e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7f6ea5b0f54021829fd0ed806f11d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25165942311286926, 'eval_f1': 0.3692307692307692, 'eval_runtime': 158.1595, 'eval_samples_per_second': 17.059, 'eval_steps_per_second': 17.059, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0062, 'learning_rate': 9.919354838709679e-06, 'epoch': 16.13}\n",
      "{'loss': 0.0047, 'learning_rate': 9.803485354097146e-06, 'epoch': 16.31}\n",
      "{'loss': 0.0072, 'learning_rate': 9.687615869484614e-06, 'epoch': 16.5}\n",
      "{'loss': 0.0054, 'learning_rate': 9.57174638487208e-06, 'epoch': 16.69}\n",
      "{'loss': 0.0085, 'learning_rate': 9.455876900259549e-06, 'epoch': 16.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5286caca804e18869f31326a15724f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26240435242652893, 'eval_f1': 0.3888888888888889, 'eval_runtime': 144.5833, 'eval_samples_per_second': 18.661, 'eval_steps_per_second': 18.661, 'epoch': 17.0}\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'SRGPTSENTNEG2\\\\pytorch_model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainSRGPT\u001b[39m.\u001b[39;49mtrain_model(\u001b[39m2\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mNEG\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39meval\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m\"\u001b[39;49m, epochs \u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\trainSRGPT.py:153\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(i, polarity, eval, epochs)\u001b[0m\n\u001b[0;32m    123\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m    124\u001b[0m     output_dir\u001b[39m=\u001b[39mouputdir,\n\u001b[0;32m    125\u001b[0m     overwrite_output_dir \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     push_to_hub\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    139\u001b[0m )\n\u001b[0;32m    141\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m    142\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    143\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 153\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    154\u001b[0m max_attempts \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m    155\u001b[0m \u001b[39mfor\u001b[39;00m attempt \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_attempts):\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\transformers\\trainer.py:1916\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1913\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m-> 1916\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[0;32m   1918\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[0;32m   1919\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1920\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\transformers\\trainer.py:2237\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[0;32m   2236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m-> 2237\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[0;32m   2238\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\transformers\\trainer.py:2396\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     torch\u001b[39m.\u001b[39msave(rng_states, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrng_state_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mprocess_index\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   2395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[1;32m-> 2396\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_push_from_checkpoint(output_dir)\n\u001b[0;32m   2398\u001b[0m \u001b[39m# Maybe delete some older checkpoints.\u001b[39;00m\n\u001b[0;32m   2399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\transformers\\trainer.py:3501\u001b[0m, in \u001b[0;36mTrainer._push_from_checkpoint\u001b[1;34m(self, checkpoint_folder)\u001b[0m\n\u001b[0;32m   3499\u001b[0m \u001b[39mfor\u001b[39;00m modeling_file \u001b[39min\u001b[39;00m modeling_files:\n\u001b[0;32m   3500\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(checkpoint_folder, modeling_file)):\n\u001b[1;32m-> 3501\u001b[0m         shutil\u001b[39m.\u001b[39;49mcopy(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(checkpoint_folder, modeling_file), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(output_dir, modeling_file))\n\u001b[0;32m   3502\u001b[0m \u001b[39m# Saving the tokenizer is fast and we don't know how many files it may have spawned, so we resave it to be sure.\u001b[39;00m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\shutil.py:419\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[0;32m    418\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[1;32m--> 419\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[0;32m    420\u001b[0m copymode(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\shutil.py:258\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(src, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[0;32m    257\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 258\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dst, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[0;32m    259\u001b[0m             \u001b[39m# macOS\u001b[39;00m\n\u001b[0;32m    260\u001b[0m             \u001b[39mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    261\u001b[0m                 \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'SRGPTSENTNEG2\\\\pytorch_model.bin'"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(2, \"NEG\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814bfee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4404   16]\n",
      " [  59   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4420\n",
      "           1       0.52      0.22      0.31        76\n",
      "\n",
      "    accuracy                           0.98      4496\n",
      "   macro avg       0.75      0.61      0.65      4496\n",
      "weighted avg       0.98      0.98      0.98      4496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(2, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b15c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe3d8e678444e4688d0cab74fe080da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(2, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8aec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7ef4c4f7d24d0792d76ca42806dd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfa766ab6a54206a687ffefcd39bc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a393b73fd404b15a9d8e0a6d9bd64a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4404   16]\n",
      " [  59   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4420\n",
      "           1       0.52      0.22      0.31        76\n",
      "\n",
      "    accuracy                           0.98      4496\n",
      "   macro avg       0.75      0.61      0.65      4496\n",
      "weighted avg       0.98      0.98      0.98      4496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(2, \"NEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e782287-053e-41f6-b23c-c16ae91aa7ac",
   "metadata": {},
   "source": [
    "## Iteration 4 - Training and Testing\n",
    "In this section, we use the data from the 4th iteration of the semi-automatic iterative algorithm for both Positive and Negative sentiment classification to train and test our BERT models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f564dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSRGPT.delete_model(4, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b419d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at jerteh/gpt2-orao and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64aec629168a40d7a7a61daaf9733eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8eac5de291452485c6784f90e7375e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTPOS4 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2d9035f3184a92bcda77db48525db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86496 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1803, 'learning_rate': 1.9884387717351092e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1677, 'learning_rate': 1.9768775434702185e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1261, 'learning_rate': 1.9653163152053275e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1307, 'learning_rate': 1.9537550869404365e-05, 'epoch': 0.74}\n",
      "{'loss': 0.114, 'learning_rate': 1.942193858675546e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66006da18c354b6497b7c0a3f497227e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09674040973186493, 'eval_f1': 0.0, 'eval_runtime': 60.1677, 'eval_samples_per_second': 44.924, 'eval_steps_per_second': 44.924, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1203, 'learning_rate': 1.9306326304106552e-05, 'epoch': 1.11}\n",
      "{'loss': 0.1112, 'learning_rate': 1.9190714021457642e-05, 'epoch': 1.29}\n",
      "{'loss': 0.097, 'learning_rate': 1.9075101738808733e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1392, 'learning_rate': 1.8959489456159823e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0938, 'learning_rate': 1.8843877173510916e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43821569a5c548fda471f1af06aecb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13638992607593536, 'eval_f1': 0.0, 'eval_runtime': 62.6641, 'eval_samples_per_second': 43.135, 'eval_steps_per_second': 43.135, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1478, 'learning_rate': 1.8728264890862006e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0947, 'learning_rate': 1.8612652608213096e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0751, 'learning_rate': 1.849704032556419e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0702, 'learning_rate': 1.838142804291528e-05, 'epoch': 2.59}\n",
      "{'loss': 0.073, 'learning_rate': 1.8265815760266373e-05, 'epoch': 2.77}\n",
      "{'loss': 0.1035, 'learning_rate': 1.8150203477617463e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b927e2bc384bc8bc680aa709ab3bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14871349930763245, 'eval_f1': 0.11111111111111109, 'eval_runtime': 60.9181, 'eval_samples_per_second': 44.371, 'eval_steps_per_second': 44.371, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0453, 'learning_rate': 1.8034591194968557e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0626, 'learning_rate': 1.7918978912319647e-05, 'epoch': 3.33}\n",
      "{'loss': 0.047, 'learning_rate': 1.7803366629670737e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0171, 'learning_rate': 1.7687754347021827e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0906, 'learning_rate': 1.757214206437292e-05, 'epoch': 3.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe5f4d5240c4e019be1a3ff6eeef5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14294204115867615, 'eval_f1': 0.2558139534883721, 'eval_runtime': 61.1255, 'eval_samples_per_second': 44.221, 'eval_steps_per_second': 44.221, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0451, 'learning_rate': 1.745652978172401e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0349, 'learning_rate': 1.7340917499075104e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0319, 'learning_rate': 1.7225305216426194e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0329, 'learning_rate': 1.7109692933777288e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0597, 'learning_rate': 1.6994080651128378e-05, 'epoch': 4.81}\n",
      "{'loss': 0.0575, 'learning_rate': 1.6878468368479468e-05, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0fff71de3341db99fc13dde5ba1630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21979837119579315, 'eval_f1': 0.2388059701492537, 'eval_runtime': 61.602, 'eval_samples_per_second': 43.878, 'eval_steps_per_second': 43.878, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0285, 'learning_rate': 1.6762856085830558e-05, 'epoch': 5.18}\n",
      "{'loss': 0.0248, 'learning_rate': 1.664724380318165e-05, 'epoch': 5.36}\n",
      "{'loss': 0.0315, 'learning_rate': 1.653163152053274e-05, 'epoch': 5.55}\n",
      "{'loss': 0.0357, 'learning_rate': 1.6416019237883835e-05, 'epoch': 5.73}\n",
      "{'loss': 0.0369, 'learning_rate': 1.6300406955234925e-05, 'epoch': 5.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa18a183a93f44cd9cbd72c42adbb9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16170959174633026, 'eval_f1': 0.28169014084507044, 'eval_runtime': 59.8973, 'eval_samples_per_second': 45.127, 'eval_steps_per_second': 45.127, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0382, 'learning_rate': 1.618479467258602e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0393, 'learning_rate': 1.606918238993711e-05, 'epoch': 6.29}\n",
      "{'loss': 0.0412, 'learning_rate': 1.59535701072882e-05, 'epoch': 6.47}\n",
      "{'loss': 0.0152, 'learning_rate': 1.5837957824639292e-05, 'epoch': 6.66}\n",
      "{'loss': 0.034, 'learning_rate': 1.5722345541990382e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae23fc605ed744c887a94e44965de144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18340787291526794, 'eval_f1': 0.19354838709677416, 'eval_runtime': 61.6805, 'eval_samples_per_second': 43.823, 'eval_steps_per_second': 43.823, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0392, 'learning_rate': 1.5606733259341472e-05, 'epoch': 7.03}\n",
      "{'loss': 0.0187, 'learning_rate': 1.5491120976692563e-05, 'epoch': 7.21}\n",
      "{'loss': 0.0066, 'learning_rate': 1.5375508694043656e-05, 'epoch': 7.4}\n",
      "{'loss': 0.0208, 'learning_rate': 1.525989641139475e-05, 'epoch': 7.58}\n",
      "{'loss': 0.0323, 'learning_rate': 1.5144284128745838e-05, 'epoch': 7.77}\n",
      "{'loss': 0.0126, 'learning_rate': 1.5028671846096931e-05, 'epoch': 7.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2078975af5fe43eab11904130389ab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17378449440002441, 'eval_f1': 0.27692307692307694, 'eval_runtime': 58.714, 'eval_samples_per_second': 46.037, 'eval_steps_per_second': 46.037, 'epoch': 8.0}\n",
      "{'train_runtime': 17100.7998, 'train_samples_per_second': 20.232, 'train_steps_per_second': 5.058, 'train_loss': 0.0656135044978188, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa4d8792d96465ab05043b182303706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/SRGPTSENTPOS4\n",
      "   d54d456..2dcde86  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/SRGPTSENTPOS4\n",
      "   2dcde86..d99b2e5  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "    6.42 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(4, \"POS\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9875e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4409   25]\n",
      " [  64    8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4434\n",
      "           1       0.24      0.11      0.15        72\n",
      "\n",
      "    accuracy                           0.98      4506\n",
      "   macro avg       0.61      0.55      0.57      4506\n",
      "weighted avg       0.97      0.98      0.98      4506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(4, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48bf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f53a50db2e436784f365e7d739e2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(4, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335ef8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30c65111e534dd69cad7e2be2bf477b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d11df4fdfe4d5084a1acaf26419670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4409   25]\n",
      " [  64    8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4434\n",
      "           1       0.24      0.11      0.15        72\n",
      "\n",
      "    accuracy                           0.98      4506\n",
      "   macro avg       0.61      0.55      0.57      4506\n",
      "weighted avg       0.97      0.98      0.98      4506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(4, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc849cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6896721408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eace355295442e3b4e262346735ed34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d4891826044c78bda82fc739655d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTNEG4 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c74ce70d9a41e296f7d9086ad1e614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 15.4k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e191cd8a2cdf4e4b8f784ecda8357ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 4.30k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36974e4727f47c88f9507d18acda3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  23%|##3       | 1.00k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fad910c38ee412bb01ad517b844587e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86496 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1333, 'learning_rate': 1.9884387717351092e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1358, 'learning_rate': 1.9768775434702185e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1011, 'learning_rate': 1.9653163152053275e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0728, 'learning_rate': 1.9537550869404365e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0804, 'learning_rate': 1.942193858675546e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59480d52a2e14c4b83aa362c58219ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21285207569599152, 'eval_f1': 0.3818181818181818, 'eval_runtime': 162.9057, 'eval_samples_per_second': 16.592, 'eval_steps_per_second': 16.592, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0371, 'learning_rate': 1.9306326304106552e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0563, 'learning_rate': 1.9190714021457642e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0688, 'learning_rate': 1.9075101738808733e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0622, 'learning_rate': 1.8959489456159823e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0864, 'learning_rate': 1.8843877173510916e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bf8a5f24d14428a20276486633831c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18004903197288513, 'eval_f1': 0.38888888888888884, 'eval_runtime': 155.9538, 'eval_samples_per_second': 17.332, 'eval_steps_per_second': 17.332, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0878, 'learning_rate': 1.8728264890862006e-05, 'epoch': 2.03}\n",
      "{'loss': 0.032, 'learning_rate': 1.8612652608213096e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0412, 'learning_rate': 1.849704032556419e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0371, 'learning_rate': 1.838142804291528e-05, 'epoch': 2.59}\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(4, \"NEG\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b7055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4426    0]\n",
      " [  80    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4426\n",
      "           1       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.98      4506\n",
      "   macro avg       0.49      0.50      0.50      4506\n",
      "weighted avg       0.96      0.98      0.97      4506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(4, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e53c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d773c3ed9dae46a0beaf996aa4901676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(4, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9237521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.2.0.dev20230928)\n",
      "    Python  3.11.5 (you have 3.11.4)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4357   69]\n",
      " [  42   38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4426\n",
      "           1       0.36      0.47      0.41        80\n",
      "\n",
      "    accuracy                           0.98      4506\n",
      "   macro avg       0.67      0.73      0.70      4506\n",
      "weighted avg       0.98      0.98      0.98      4506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(4, \"NEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519f333-3fb7-4dfd-8674-3595bfd236ab",
   "metadata": {},
   "source": [
    "## Iteration 6 - Training and Testing\n",
    "In this section, we use the data from the 6th iteration of the semi-automatic iterative algorithm for both Positive and Negative sentiment classification to train and test our BERT models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65724648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44633db317014b93a0e213d6040592bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0783636ac6bc463e8874be54ad16ab06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/832k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5558583b8d40f0868aa46e82f725d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/498k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654cc44c087b4e0ab5984be90dfa9f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc645c13eb44702b19e6c1be5551569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9625b130ad4d9e87dc6d5b58e8358f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f5abab85b948ef8572c7fa468a2a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a317fcc892f435a8e4568c311138919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2b504418f4430c99f54a9697d1cb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2707 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe11cbd796c45d4935ac2a48d4d4d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTPOS6 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ced3e8c6d7452e8fe59398268dae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 8.00k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed82800c0ba948a7aed244a27e2ac01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 4.30k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62eab64f069f4aa59d8e73d1a29182df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  23%|##3       | 1.00k/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08985771608445df90d53ef839d229d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86592 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.002, 'learning_rate': 1.9884515890613453e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0061, 'learning_rate': 1.9769031781226905e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0032, 'learning_rate': 1.9653547671840356e-05, 'epoch': 0.55}\n",
      "{'loss': 0.015, 'learning_rate': 1.9538063562453808e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0145, 'learning_rate': 1.942257945306726e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a85bf0ea9e40e6b82dc2781a9cbf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48092132806777954, 'eval_f1': 0.2526315789473684, 'eval_runtime': 59.2796, 'eval_samples_per_second': 45.665, 'eval_steps_per_second': 45.665, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0112, 'learning_rate': 1.930709534368071e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0119, 'learning_rate': 1.9191611234294163e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0098, 'learning_rate': 1.9076127124907614e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0141, 'learning_rate': 1.8960643015521066e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0052, 'learning_rate': 1.8845158906134518e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f013ab7ad44461901b851d173390ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35108986496925354, 'eval_f1': 0.15625, 'eval_runtime': 61.1611, 'eval_samples_per_second': 44.26, 'eval_steps_per_second': 44.26, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0046, 'learning_rate': 1.872967479674797e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0026, 'learning_rate': 1.861419068736142e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0057, 'learning_rate': 1.8498706577974872e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0041, 'learning_rate': 1.8383222468588324e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0085, 'learning_rate': 1.8267738359201775e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0136, 'learning_rate': 1.8152254249815227e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464c2eb49f79429b8b26ab163d2cde15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36203038692474365, 'eval_f1': 0.2222222222222222, 'eval_runtime': 146.7049, 'eval_samples_per_second': 18.452, 'eval_steps_per_second': 18.452, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.803677014042868e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0075, 'learning_rate': 1.792128603104213e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0034, 'learning_rate': 1.7805801921655582e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0196, 'learning_rate': 1.7690317812269033e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0028, 'learning_rate': 1.7574833702882485e-05, 'epoch': 3.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dea7246f2a447c909aa1f9ac65a690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3375719487667084, 'eval_f1': 0.15384615384615383, 'eval_runtime': 151.6393, 'eval_samples_per_second': 17.852, 'eval_steps_per_second': 17.852, 'epoch': 4.0}\n",
      "{'train_runtime': 11492.4959, 'train_samples_per_second': 30.139, 'train_steps_per_second': 7.535, 'train_loss': 0.007788614468361304, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cf7bcddbb74122bc64402dc64517e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF\n",
      "EOF\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTPOS6'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push attempt 1 failed with error: EOF\n",
      "EOF\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTPOS6'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3e79ec14ff40278fd5e20d3c626c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/SRGPTSENTPOS6\n",
      "   fa1e076..a7f3b79  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "    6.42 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(6, \"POS\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb4cae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4381   57]\n",
      " [  55   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4438\n",
      "           1       0.24      0.25      0.24        73\n",
      "\n",
      "    accuracy                           0.98      4511\n",
      "   macro avg       0.61      0.62      0.62      4511\n",
      "weighted avg       0.98      0.98      0.98      4511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(6, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864e41c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ce59f0c0ac4e6583064802c4342943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(6, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42991d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3818de51286d4dac8c0dfd93af9d0a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9ea236b10b4912baf6ff7a20aabf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d513bd70429f46cfa399668307092639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b236b3ecefb243ae9e1229b88c3375a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/832k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af62917423db45078f468feb34706bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/498k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e923d9e4cb4a209f6fb8cb38447b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242ebf374d74424e990655212fd3d7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b503542fb2d4f5dbe58e506dee4480b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4381   57]\n",
      " [  55   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4438\n",
      "           1       0.24      0.25      0.24        73\n",
      "\n",
      "    accuracy                           0.98      4511\n",
      "   macro avg       0.61      0.62      0.62      4511\n",
      "weighted avg       0.98      0.98      0.98      4511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(6, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c732c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bf8f54e67948ce9ef1e22d8c4b6850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45895c1d95724ad0b82e339406917e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/832k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e5182924964e23906172356046e62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/498k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11ae45fb63340bebe23f54d6d76d99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28a86dea1a44f3a8a9ff0cce3caaa6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd1c44702e7489da2a445c3f4343e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45e3529d741430e8bb9e430ca42c6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdbddf7d5d34d80abb49719a731d7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6896721408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479997e180fb422f91bb90206b86105f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2707 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5217104107b44463977daef944f02825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/SRGPTSENTNEG6 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4408fd2832649cbb049eddcb2fc569f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 15.4k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f60265658d743379dff6915ee921509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3225a96522724ca89c5b9da17dc301c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86592 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2043, 'learning_rate': 1.9884515890613453e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1571, 'learning_rate': 1.9769031781226905e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1371, 'learning_rate': 1.9653547671840356e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1562, 'learning_rate': 1.9538063562453808e-05, 'epoch': 0.74}\n",
      "{'loss': 0.1385, 'learning_rate': 1.942257945306726e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f71c177b9b4860830a5c5bdfba2bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1402807980775833, 'eval_f1': 0.0, 'eval_runtime': 59.4355, 'eval_samples_per_second': 45.545, 'eval_steps_per_second': 45.545, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1317, 'learning_rate': 1.930709534368071e-05, 'epoch': 1.11}\n",
      "{'loss': 0.1625, 'learning_rate': 1.9191611234294163e-05, 'epoch': 1.29}\n",
      "{'loss': 0.1235, 'learning_rate': 1.9076127124907614e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1538, 'learning_rate': 1.8960643015521066e-05, 'epoch': 1.66}\n",
      "{'loss': 0.1099, 'learning_rate': 1.8845158906134518e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e3a7296d834bd4bc8fc885ad74f237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10935695469379425, 'eval_f1': 0.0, 'eval_runtime': 58.3621, 'eval_samples_per_second': 46.383, 'eval_steps_per_second': 46.383, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1226, 'learning_rate': 1.872967479674797e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0823, 'learning_rate': 1.861419068736142e-05, 'epoch': 2.22}\n",
      "{'loss': 0.1056, 'learning_rate': 1.8498706577974872e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0934, 'learning_rate': 1.8383222468588324e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0758, 'learning_rate': 1.8267738359201775e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0738, 'learning_rate': 1.8152254249815227e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d34cb73041a4754a19807ab9208d25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2505303621292114, 'eval_f1': 0.24242424242424243, 'eval_runtime': 57.8953, 'eval_samples_per_second': 46.757, 'eval_steps_per_second': 46.757, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0543, 'learning_rate': 1.803677014042868e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0446, 'learning_rate': 1.792128603104213e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0523, 'learning_rate': 1.7805801921655582e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0382, 'learning_rate': 1.7690317812269033e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0431, 'learning_rate': 1.7574833702882485e-05, 'epoch': 3.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22326fa4253f44a3900f2d62f164d028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1801680475473404, 'eval_f1': 0.2647058823529412, 'eval_runtime': 57.8293, 'eval_samples_per_second': 46.81, 'eval_steps_per_second': 46.81, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0338, 'learning_rate': 1.7459349593495937e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0437, 'learning_rate': 1.7343865484109388e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0176, 'learning_rate': 1.722838137472284e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0302, 'learning_rate': 1.711289726533629e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0233, 'learning_rate': 1.6997413155949743e-05, 'epoch': 4.8}\n",
      "{'loss': 0.0453, 'learning_rate': 1.6881929046563195e-05, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dedd55196a48f8b7146af7f2616b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2628609240055084, 'eval_f1': 0.22857142857142856, 'eval_runtime': 58.0727, 'eval_samples_per_second': 46.614, 'eval_steps_per_second': 46.614, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0117, 'learning_rate': 1.6766444937176646e-05, 'epoch': 5.17}\n",
      "{'loss': 0.0083, 'learning_rate': 1.6650960827790098e-05, 'epoch': 5.36}\n",
      "{'loss': 0.046, 'learning_rate': 1.653547671840355e-05, 'epoch': 5.54}\n",
      "{'loss': 0.0087, 'learning_rate': 1.6419992609017e-05, 'epoch': 5.73}\n",
      "{'loss': 0.0278, 'learning_rate': 1.6304508499630452e-05, 'epoch': 5.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ffcfb45a1a486490fb5ce36e2cfc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2564699649810791, 'eval_f1': 0.3488372093023256, 'eval_runtime': 60.3666, 'eval_samples_per_second': 44.843, 'eval_steps_per_second': 44.843, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0168, 'learning_rate': 1.6189024390243904e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0236, 'learning_rate': 1.6073540280857356e-05, 'epoch': 6.28}\n",
      "{'loss': 0.0124, 'learning_rate': 1.5958056171470807e-05, 'epoch': 6.47}\n",
      "{'loss': 0.0334, 'learning_rate': 1.584257206208426e-05, 'epoch': 6.65}\n",
      "{'loss': 0.032, 'learning_rate': 1.572708795269771e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb38b89ee8c4766a9d9becc9d9f0c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2739080488681793, 'eval_f1': 0.2962962962962963, 'eval_runtime': 59.821, 'eval_samples_per_second': 45.252, 'eval_steps_per_second': 45.252, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (6) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0043, 'learning_rate': 1.5611603843311162e-05, 'epoch': 7.02}\n",
      "{'loss': 0.0172, 'learning_rate': 1.5496119733924614e-05, 'epoch': 7.21}\n",
      "{'loss': 0.0201, 'learning_rate': 1.5380635624538065e-05, 'epoch': 7.39}\n",
      "{'loss': 0.0122, 'learning_rate': 1.5265151515151517e-05, 'epoch': 7.58}\n",
      "{'loss': 0.0122, 'learning_rate': 1.5149667405764967e-05, 'epoch': 7.76}\n",
      "{'loss': 0.0402, 'learning_rate': 1.503418329637842e-05, 'epoch': 7.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c6adfad74f4241b2e4be79fd4780d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21845291554927826, 'eval_f1': 0.2857142857142857, 'eval_runtime': 57.5626, 'eval_samples_per_second': 47.027, 'eval_steps_per_second': 47.027, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0119, 'learning_rate': 1.4918699186991872e-05, 'epoch': 8.13}\n",
      "{'loss': 0.0074, 'learning_rate': 1.4803215077605321e-05, 'epoch': 8.31}\n",
      "{'loss': 0.0086, 'learning_rate': 1.4687730968218775e-05, 'epoch': 8.5}\n",
      "{'loss': 0.0221, 'learning_rate': 1.4572246858832226e-05, 'epoch': 8.68}\n",
      "{'loss': 0.0251, 'learning_rate': 1.4456762749445676e-05, 'epoch': 8.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c27e0a4056442018b3d21202a1e9077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23453719913959503, 'eval_f1': 0.273972602739726, 'eval_runtime': 58.7203, 'eval_samples_per_second': 46.1, 'eval_steps_per_second': 46.1, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:428: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0108, 'learning_rate': 1.4341278640059128e-05, 'epoch': 9.05}\n",
      "{'loss': 0.0098, 'learning_rate': 1.4225794530672581e-05, 'epoch': 9.24}\n",
      "{'loss': 0.0102, 'learning_rate': 1.4110310421286033e-05, 'epoch': 9.42}\n",
      "{'loss': 0.0092, 'learning_rate': 1.3994826311899483e-05, 'epoch': 9.61}\n",
      "{'loss': 0.0064, 'learning_rate': 1.3879342202512936e-05, 'epoch': 9.79}\n",
      "{'loss': 0.0284, 'learning_rate': 1.3763858093126387e-05, 'epoch': 9.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f6f47875ae4ad0ab7e90a5cf69b457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25835371017456055, 'eval_f1': 0.2777777777777778, 'eval_runtime': 57.9859, 'eval_samples_per_second': 46.684, 'eval_steps_per_second': 46.684, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 21045.6982, 'train_samples_per_second': 16.458, 'train_steps_per_second': 4.114, 'train_loss': 0.05416921397366901, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (10) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "fatal: unable to access 'https://huggingface.co/Tanor/SRGPTSENTNEG6/': Could not resolve host: huggingface.co\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push attempt 1 failed with error: fatal: unable to access 'https://huggingface.co/Tanor/SRGPTSENTNEG6/': Could not resolve host: huggingface.co\n",
      "\n",
      "Push attempt 2 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7CEA0F6D0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: f6048bd5-6e67-45c3-a752-34ee920f7a15)')\n",
      "Push attempt 3 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2DA7190>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: c066f77e-70a9-457e-b1f5-48e33257dc55)')\n",
      "Push attempt 4 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2C55F90>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: eead88de-a94c-4f38-b9f1-700d4e53703a)')\n",
      "Push attempt 5 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2DA4C10>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 2cff161e-8b29-4045-9c0f-221404f69661)')\n",
      "Push attempt 6 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2D12B10>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: e0425687-5276-4284-bb82-aca0b1738f02)')\n",
      "Push attempt 7 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2DD7190>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 14f23de6-bcfc-414d-881b-79152695900e)')\n",
      "Push attempt 8 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2C57A50>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 96ce9889-67e5-49e2-a7e6-afd101fe8d47)')\n",
      "Push attempt 9 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2DD4890>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 90a855ad-1d2d-4c0f-a73e-abed5211312c)')\n",
      "Push attempt 10 failed with error: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/Tanor/SRGPTSENTNEG6 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A7D2D13190>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: cf4ca17b-1713-4c5e-9e72-8bcd73a417a8)')\n",
      "All push attempts failed.\n",
      "Max memory allocated by tensors:\n",
      "    6.42 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.train_model(6, \"NEG\", eval=\"f1\", epochs =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58df753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4406   21]\n",
      " [  58   26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4427\n",
      "           1       0.55      0.31      0.40        84\n",
      "\n",
      "    accuracy                           0.98      4511\n",
      "   macro avg       0.77      0.65      0.69      4511\n",
      "weighted avg       0.98      0.98      0.98      4511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model_local(6, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536fc5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a0f51c86ad4d95890cd7e0a17e1467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSRGPT.upload_local_model_to_hub(6, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdc3c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4406   21]\n",
      " [  58   26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4427\n",
      "           1       0.55      0.31      0.40        84\n",
      "\n",
      "    accuracy                           0.98      4511\n",
      "   macro avg       0.77      0.65      0.69      4511\n",
      "weighted avg       0.98      0.98      0.98      4511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSRGPT.test_model(6, \"NEG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
