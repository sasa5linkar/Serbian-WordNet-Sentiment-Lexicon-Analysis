{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning a Classification Model\n",
    "\n",
    "In this notebook, I experimented with finetuning a classification model by training only the classification layer. However, the results were not satisfying, so I decided not to expand the experiment further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainSRGPTfrozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with frozen all but classifier head. It does not give good results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSRGPTfrozen.delete_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at jerteh/gpt2-orao and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6407475200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b4c51c06e04d998c59b03e53d3c429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2667 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c1183ad43845f59231b338e1b21277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10665 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/ORAOFROZENPOS0 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d6414ddb72477e90d1ce8b94629d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0936, 'learning_rate': 1.97655663915979e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0652, 'learning_rate': 1.9531132783195802e-05, 'epoch': 0.38}\n",
      "{'loss': 0.086, 'learning_rate': 1.92966991747937e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0587, 'learning_rate': 1.90622655663916e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0789, 'learning_rate': 1.88278319579895e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f0b4a02f0e48c4b8391e4ccb9cebdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0810864046216011, 'eval_f1': 0.0, 'eval_runtime': 58.9486, 'eval_samples_per_second': 45.243, 'eval_steps_per_second': 45.243, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0737, 'learning_rate': 1.85933983495874e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0933, 'learning_rate': 1.8358964741185298e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0877, 'learning_rate': 1.8124531132783196e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0916, 'learning_rate': 1.7890097524381094e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0776, 'learning_rate': 1.7655663915978996e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6add00c39b594fca90bec328d8bd4742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08138421177864075, 'eval_f1': 0.0, 'eval_runtime': 58.9853, 'eval_samples_per_second': 45.215, 'eval_steps_per_second': 45.215, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0538, 'learning_rate': 1.7421230307576895e-05, 'epoch': 2.06}\n",
      "{'loss': 0.075, 'learning_rate': 1.7186796699174793e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1078, 'learning_rate': 1.6952363090772695e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0678, 'learning_rate': 1.6717929482370593e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0446, 'learning_rate': 1.6483495873968492e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c3d77c0d1548ba95cb3b6bfe757531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08015435934066772, 'eval_f1': 0.0, 'eval_runtime': 58.3653, 'eval_samples_per_second': 45.695, 'eval_steps_per_second': 45.695, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.123, 'learning_rate': 1.6249062265566394e-05, 'epoch': 3.0}\n",
      "{'loss': 0.1065, 'learning_rate': 1.6014628657164292e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0957, 'learning_rate': 1.5780195048762194e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0441, 'learning_rate': 1.5545761440360093e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0732, 'learning_rate': 1.531132783195799e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0875, 'learning_rate': 1.5076894223555891e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a402340798d74c5f8d4e056f334014d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08088871091604233, 'eval_f1': 0.0, 'eval_runtime': 58.2845, 'eval_samples_per_second': 45.758, 'eval_steps_per_second': 45.758, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0727, 'learning_rate': 1.4842460615153788e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0636, 'learning_rate': 1.4608027006751688e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0931, 'learning_rate': 1.4373593398349588e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0786, 'learning_rate': 1.4139159789947488e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0539, 'learning_rate': 1.3904726181545387e-05, 'epoch': 4.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2551a192304971912fa9a7dae884fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07999750971794128, 'eval_f1': 0.0, 'eval_runtime': 58.2442, 'eval_samples_per_second': 45.79, 'eval_steps_per_second': 45.79, 'epoch': 5.0}\n",
      "{'train_runtime': 2088.4738, 'train_samples_per_second': 81.706, 'train_steps_per_second': 20.424, 'train_loss': 0.08008227792936884, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca87f889c57b45b6964bcff3f53f12bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/ORAOFROZENPOS0\n",
      "   fe15e88..f6861fd  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/ORAOFROZENPOS0\n",
      "   f6861fd..344a040  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "    6.04 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPTfrozen.train_model(0, \"POS\", eval=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f933eb608042c180ea05331d80a79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.2.0.dev20230928)\n",
      "    Python  3.11.5 (you have 3.11.4)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4408    0]\n",
      " [  37    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4408\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.99      4445\n",
      "   macro avg       0.50      0.50      0.50      4445\n",
      "weighted avg       0.98      0.99      0.99      4445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\HugFace\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainSRGPTfrozen.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(49152, 1280)\n",
      "    (wpe): Embedding(1024, 1280)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-35): 36 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=1280, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)import trainSRGPTfrozen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainSRGPTfrozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Frozen Embedding\n",
    "\n",
    "In this experiment, I tested the performance of the model with frozen embeddings. The following steps were taken:\n",
    "\n",
    "1. Deleted the previous model using `trainSRGPTfrozen.delete_model(0, \"POS\")` (CELL INDEX: 9)\n",
    "2. Trained the model with frozen embeddings using `trainSRGPTfrozen.train_model(0, \"POS\", eval=\"f1\")` (CELL INDEX: 10)\n",
    "3. Tested the model using `trainSRGPTfrozen.test_model(0, \"POS\")` (CELL INDEX: 11)\n",
    "\n",
    "The results of the experiment are as follows: \n",
    "\n",
    "Testing with frozen embedding did not improve the performance of the model. The accuracy and F1 score were lower than the previous experiment. Therefore, I decided not to pursue this approach further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSRGPTfrozen.delete_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at jerteh/gpt2-orao and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175c8bffc97a46c7ad9b82e42e7b8761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2667 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f616176d1540ba84d5ef760626e3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10665 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/ORAOFROZENPOS0 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222482cfc3bf468ebddf29e1f212eb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0944, 'learning_rate': 1.97655663915979e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0635, 'learning_rate': 1.9531132783195802e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0842, 'learning_rate': 1.92966991747937e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0575, 'learning_rate': 1.90622655663916e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0771, 'learning_rate': 1.88278319579895e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa41845889664c0cafb684014229182a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07983051985502243, 'eval_f1': 0.0, 'eval_runtime': 58.1412, 'eval_samples_per_second': 45.871, 'eval_steps_per_second': 45.871, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0724, 'learning_rate': 1.85933983495874e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0922, 'learning_rate': 1.8358964741185298e-05, 'epoch': 1.31}\n",
      "{'loss': 0.087, 'learning_rate': 1.8124531132783196e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0911, 'learning_rate': 1.7890097524381094e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0769, 'learning_rate': 1.7655663915978996e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84be8119bed84d7fb87657cdfa0431d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08016818761825562, 'eval_f1': 0.0, 'eval_runtime': 60.0183, 'eval_samples_per_second': 44.436, 'eval_steps_per_second': 44.436, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0532, 'learning_rate': 1.7421230307576895e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0742, 'learning_rate': 1.7186796699174793e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1053, 'learning_rate': 1.6952363090772695e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0665, 'learning_rate': 1.6717929482370593e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0437, 'learning_rate': 1.6483495873968492e-05, 'epoch': 2.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9908094d260f4e9fb4c19d1a398b85a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07896683365106583, 'eval_f1': 0.0, 'eval_runtime': 59.1108, 'eval_samples_per_second': 45.119, 'eval_steps_per_second': 45.119, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1209, 'learning_rate': 1.6249062265566394e-05, 'epoch': 3.0}\n",
      "{'loss': 0.1052, 'learning_rate': 1.6014628657164292e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0941, 'learning_rate': 1.5780195048762194e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0432, 'learning_rate': 1.5545761440360093e-05, 'epoch': 3.56}\n",
      "{'loss': 0.072, 'learning_rate': 1.531132783195799e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0875, 'learning_rate': 1.5076894223555891e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f05aa28ea5048c3bab71b260273afb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07980107516050339, 'eval_f1': 0.0, 'eval_runtime': 60.739, 'eval_samples_per_second': 43.909, 'eval_steps_per_second': 43.909, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\torch\\utils\\checkpoint.py:66: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0724, 'learning_rate': 1.4842460615153788e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0633, 'learning_rate': 1.4608027006751688e-05, 'epoch': 4.31}\n",
      "{'loss': 0.093, 'learning_rate': 1.4373593398349588e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0768, 'learning_rate': 1.4139159789947488e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0531, 'learning_rate': 1.3904726181545387e-05, 'epoch': 4.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fb3a60c4ec4dfebc28068c877d6680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07890400290489197, 'eval_f1': 0.0, 'eval_runtime': 61.3522, 'eval_samples_per_second': 43.47, 'eval_steps_per_second': 43.47, 'epoch': 5.0}\n",
      "{'train_runtime': 2158.6298, 'train_samples_per_second': 79.05, 'train_steps_per_second': 19.761, 'train_loss': 0.0790761570339934, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b932cd641f459b954f62a564dc7c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/ORAOFROZENPOS0\n",
      "   a1b1d93..f3483bf  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/ORAOFROZENPOS0\n",
      "   f3483bf..7c229ac  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "    3.05 GB\n"
     ]
    }
   ],
   "source": [
    "trainSRGPTfrozen.train_model(0, \"POS\", eval=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a3d08636d943b1acce65a03827d39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.2.0.dev20230928)\n",
      "    Python  3.11.5 (you have 3.11.4)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4408    0]\n",
      " [  37    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4408\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.99      4445\n",
      "   macro avg       0.50      0.50      0.50      4445\n",
      "weighted avg       0.98      0.99      0.99      4445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sasa5\\anaconda3\\envs\\hugface\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainSRGPTfrozen.test_model(0, \"POS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HugFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
